# -*- coding: utf-8 -*-
import threading
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os
from flask import Flask
import pandas as pd

# ğŸ” ë””ë§ˆë‹ˆì½” ì •ë³´
BOT_TOKEN = 'ì—¬ê¸°ì—_í…”ë ˆê·¸ë¨_BOT_TOKEN'
CHAT_ID = 'ì—¬ê¸°ì—_CHAT_ID'
SHEET_NAME = 'ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ íŠ¸ë˜ì»¤'

# ğŸŒ Flask ì„œë²„ (Renderì—ì„œ ì¢…ë£Œ ë°©ì§€ìš©)
app = Flask(__name__)
@app.route('/')
def home():
    return "ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ë´‡ ì‘ë™ ì¤‘!"

def run_flask():
    app.run(host='0.0.0.0', port=10000)

# ğŸ“¥ KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
def get_krx_stock_list():
    url = "https://kind.krx.co.kr/corpgeneral/corpList.do?method=download"
    df = pd.read_html(url, encoding='cp949')[0]
    df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].apply(lambda x: f"{x:06d}")
    return dict(zip(df['íšŒì‚¬ëª…'], df['ì¢…ëª©ì½”ë“œ']))

stock_dict = get_krx_stock_list()

# ğŸ” ë‰´ìŠ¤ ë³¸ë¬¸ ì—´ì–´ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
def extract_stock_from_article(title, url, stock_dict):
    text = title
    try:
        res = requests.get(url, timeout=3)
        soup = BeautifulSoup(res.text, 'html.parser')
        body = soup.get_text()
        text += body
    except:
        pass

    for name in stock_dict.keys():
        if name in text:
            return name, stock_dict[name]
    return None, None

# ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ (ê¸ˆìœµ ë©”ì¸)
def get_naver_finance_news():
    news_list = []
    url = "https://finance.naver.com/news/mainnews.naver"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, "html.parser")
    for a in soup.select(".mainNewsList li a"):
        title = a.get_text(strip=True)
        link = "https://finance.naver.com" + a['href']
        if title:
            news_list.append((link, title))
    return news_list

# ğŸ“° ë„¤ì´ë²„ ì¼ë°˜ ë­í‚¹ ë‰´ìŠ¤ í¬ë¡¤ë§
def get_naver_general_news():
    news_list = []
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, "html.parser")
    for a in soup.select("ul.ranking_list li a"):
        title = a.get_text(strip=True)
        link = "https://news.naver.com" + a['href']
        if title:
            news_list.append((link, title))
    return news_list

# ğŸ“„ êµ¬ê¸€ì‹œíŠ¸ ì—°ê²°
def connect_sheet():
    key_json = os.environ.get('GOOGLE_KEY_JSON')
    if not key_json:
        print("âŒ GOOGLE_KEY_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ!")
        exit()

    key_dict = json.loads(key_json)
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    client = gspread.authorize(creds)
    sheet = client.open(SHEET_NAME).sheet1
    return sheet

sheet = connect_sheet()

# ğŸ—‚ï¸ ì‹œíŠ¸ ê¸°ë¡
def log_to_sheet(sheet, title, link):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sheet.append_row([now, title, link])
    print(f"[ì‹œíŠ¸ ê¸°ë¡ë¨] {title}")

# ğŸ’¬ í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram_news(title, link):
    message = f"""[ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤]

{title}
{link}
"""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'text': message,
        'parse_mode': 'HTML',
        'disable_web_page_preview': False
    }
    response = requests.post(url, data=data)
    print(f"[í…”ë ˆê·¸ë¨ ì‘ë‹µ] {response.text}")

# ğŸ” ë‰´ìŠ¤ ë£¨í”„ ì‹œì‘
def start_news_loop():
    old_links = []
    while True:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ë£¨í”„ ëŒê³  ìˆìŒ...")

        all_news = get_naver_finance_news() + get_naver_general_news()
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê°œìˆ˜: {len(all_news)}")

        for link, title in all_news:
            if link not in old_links:
                stock_name, stock_code = extract_stock_from_article(title, link, stock_dict)
                if stock_name:
                    title = f"[{stock_name}] {title}"
                    send_telegram_news(title, link)
                    log_to_sheet(sheet, title, link)
                    old_links.append(link)
                    if len(old_links) > 30:
                        old_links.pop(0)

        time.sleep(60)

# âœ… ë©”ì¸ ì‹¤í–‰ ì¡°ê±´
if __name__ == "__main__":
    threading.Thread(target=run_flask).start()
    threading.Thread(target=start_news_loop).start()
