import os
import time
import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# ë””ë§ˆë‹ˆì½” ì „ìš© ì„¤ì •ê°’
BOT_TOKEN = '8059473480:AAHWayTZDViTfTk-VtCAmPxvYAmTrjhtMMs'
CHAT_ID = '2037756724'
SHEET_NAME = 'ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ íŠ¸ë˜ì»¤'
MAX_SEND_PER_LOOP = 5  # ë£¨í”„ë‹¹ ì „ì†¡ ê°œìˆ˜ ì œí•œ

# âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_google_sheet(sheet_name):
    key_json = os.environ.get('GOOGLE_KEY_JSON')
    if not key_json:
        print("âŒ GOOGLE_KEY_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ!")
        exit()
    key_dict = json.loads(key_json)
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    client = gspread.authorize(creds)
    return client.open(sheet_name)

sheet = connect_google_sheet(SHEET_NAME)

# âœ… ë‚ ì§œë³„ ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸°
def get_daily_worksheet(sheet):
    today = datetime.now().strftime('%Y-%m-%d')
    try:
        worksheet = sheet.worksheet(today)
    except gspread.exceptions.WorksheetNotFound:
        worksheet = sheet.add_worksheet(title=today, rows="1000", cols="4")
        worksheet.append_row(["ê¸°ë¡ì‹œê°„", "ì„¹ì…˜", "ë‰´ìŠ¤ì œëª©", "ë§í¬"])
    return worksheet

# âœ… ì‹œíŠ¸ì— ê¸°ë¡
def log_to_sheet(sheet, section, title, link):
    worksheet = get_daily_worksheet(sheet)
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    worksheet.append_row([now, section, title, link])
    print(f"[ì‹œíŠ¸ ê¸°ë¡ë¨] {title}")

# âœ… ë„¤ì´ë²„ ë­í‚¹ ë‰´ìŠ¤ ìˆ˜ì§‘ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ + ì–¸ë¡ ì‚¬ë³„ TOP 1)
def get_ranking_news():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, 'html.parser')

    news_list = []
    categories = soup.select(".rankingnews_box")

    for category in categories:
        category_name = category.select_one("h4.rankingnews_box_title").get_text(strip=True)
        media_groups = category.select(".rankingnews_box_inner")

        for media in media_groups:
            press_name_tag = media.select_one(".rankingnews_name")
            press_name = press_name_tag.get_text(strip=True) if press_name_tag else "ì–¸ë¡ ì‚¬ ì—†ìŒ"

            articles = media.select("li")
            if articles:
                li = articles[0]  # âœ… 1ìœ„ ê¸°ì‚¬ë§Œ
                a_tag = li.select_one("a")
                img_tag = li.select_one("img")
                if a_tag:
                    title = a_tag.get_text(strip=True)
                    link = a_tag['href']
                    img_url = img_tag['src'] if img_tag else None
                    full_section = f"{category_name} - {press_name}"
                    news_list.append((full_section, 1, title, link, img_url))

    return news_list

# âœ… í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram(section, rank, title, link, img_url=None):
    message = f"""ğŸ“¢ <b>[{section} TOP {rank}]</b>\n\n{title}\n{link}"""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto" if img_url else f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'caption': message if img_url else None,
        'photo': img_url if img_url else None,
        'text': None if img_url else message,
        'parse_mode': 'HTML',
        'disable_web_page_preview': False
    }
    try:
        response = requests.post(url, data={k: v for k, v in data.items() if v is not None})
        if response.status_code == 429:
            retry_after = response.json().get("parameters", {}).get("retry_after", 60)
            print(f"ğŸ” ë„ˆë¬´ ë§ì€ ìš”ì²­! {retry_after}ì´ˆ ëŒ€ê¸°")
            time.sleep(retry_after + 1)
        else:
            print(f"[í…”ë ˆê·¸ë¨ ì‘ë‹µ] {response.text}")
    except Exception as e:
        print(f"[í…”ë ˆê·¸ë¨ ì—ëŸ¬] {e}")

# âœ… ì‹¤í–‰ ë£¨í”„
first_run = True
old_links = []

while True:
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ë£¨í”„ ì‘ë™ ì¤‘...")
    news_items = get_ranking_news()
    count = 0

    for section, rank, title, link, img_url in news_items:
        if link not in old_links:
            if not first_run:
                send_telegram(section, rank, title, link, img_url)
                log_to_sheet(sheet, section, title, link)
                count += 1
                time.sleep(1)
            old_links.append(link)

            if count >= MAX_SEND_PER_LOOP:
                print("âš ï¸ ì „ì†¡ ì œí•œ ë„ë‹¬. ë‹¤ìŒ ë£¨í”„ê¹Œì§€ ëŒ€ê¸°.")
                break

    if first_run:
        print("ğŸ”• ì²« ë£¨í”„ì—ì„œëŠ” ë‰´ìŠ¤ ì „ì†¡ ì—†ì´ ë§í¬ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
        first_run = False

    if len(old_links) > 100:
        old_links = old_links[-50:]

    time.sleep(60)
