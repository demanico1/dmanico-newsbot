import os
import time
import json
import threading
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from flask import Flask
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import traceback
import builtins

# ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥
real_print = builtins.print
builtins.print = lambda *args, **kwargs: real_print(*args, **{**kwargs, "flush": True})

# ì„¤ì •
BOT_TOKEN = '8059473480:AAHWayTZDViTfTk-VtCAmPxvYAmTrjhtMMs'
CHAT_ID = '2037756724'
SHEET_NAME = 'ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ íŠ¸ë˜ì»¤'
MAX_SEND_PER_LOOP = 3
LINK_CACHE_FILE = 'old_links.json'

# KST ì‹œê°„
def now_kst():
    return datetime.utcnow() + timedelta(hours=9)

# ì œëª© ìë¥´ê¸°
def shorten_title(title, max_len=100):
    return title if len(title) <= max_len else title[:max_len] + "..."

# Flask ì„œë²„
app = Flask(__name__)
@app.route('/')
def home():
    return "ğŸŸ¢ ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ë´‡ ì‘ë™ ì¤‘"

# êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_google_sheet(sheet_name):
    key_json = os.environ.get('GOOGLE_KEY_JSON')
    if not key_json:
        print("âŒ GOOGLE_KEY_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ!")
        exit()
    key_dict = json.loads(key_json)
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    client = gspread.authorize(creds)
    return client.open(sheet_name)

sheet = connect_google_sheet(SHEET_NAME)

# ì‹œíŠ¸ ê¸°ë¡
def get_daily_worksheet(sheet):
    today = now_kst().strftime('%Y-%m-%d')
    try:
        worksheet = sheet.worksheet(today)
    except gspread.exceptions.WorksheetNotFound:
        worksheet = sheet.add_worksheet(title=today, rows="1000", cols="4")
        worksheet.append_row(["ê¸°ë¡ì‹œê°„", "ë‰´ìŠ¤ì œëª©", "ë§í¬", "ì–¸ë¡ ì‚¬"])
    return worksheet

def log_to_sheet(sheet, title, link, press):
    worksheet = get_daily_worksheet(sheet)
    now = now_kst().strftime("%Y-%m-%d %H:%M:%S")
    try:
        worksheet.append_row([now, title, link, press])
        print(f"[ì‹œíŠ¸ ê¸°ë¡ë¨] {title}")
    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ ê¸°ë¡ ì‹¤íŒ¨:")
        traceback.print_exc()

# í”„ë¦¬ë·° ì œëª© ì¶”ì¶œ
def extract_preview_title(url):
    try:
        print(f"ğŸ” í”„ë¦¬ë·° ì œëª© ì¶”ì¶œ ì‹œë„: {url}")
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            preview_title = og_title['content'].strip()
            print(f"âœ… í”„ë¦¬ë·° ì œëª© ì¶”ì¶œ ì„±ê³µ: {preview_title}")
            return preview_title
        else:
            print("âš ï¸ og:title ë©”íƒ€íƒœê·¸ ì—†ìŒ")
    except Exception as e:
        print(f"âŒ í”„ë¦¬ë·° ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None

# ë‰´ìŠ¤ ìˆ˜ì§‘
def get_live_news():
    url = "https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001"
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []

    news_list = []
    for li in soup.select("ul.type06_headline li"):
        a_tag = li.select_one("a")
        press = li.select_one(".writing")
        if a_tag and press:
            title = a_tag.get_text(strip=True)
            link = a_tag['href']
            press_name = press.get_text(strip=True)
            news_list.append((title, link, press_name))
    return news_list

# í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram(title, link, press):
    preview_title = extract_preview_title(link)
    final_title = shorten_title(preview_title) if preview_title else shorten_title(title)

    message = f"""{link}

ğŸ“° <b>{final_title}</b>  <i>[{press}]</i>"""

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'text': message,
        'parse_mode': 'HTML',
        'disable_web_page_preview': False
    }
    try:
        requests.post(url, data=data)
        print(f"ğŸ“¤ í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ: {final_title}")
    except Exception as e:
        print(f"âŒ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨:")
        traceback.print_exc()

# ë‰´ìŠ¤ ë£¨í”„
def news_loop():
    old_links = load_old_links()
    while True:
        now = now_kst().strftime('%H:%M:%S')
        print(f"\nğŸ” [{now}] ë‰´ìŠ¤ ë£¨í”„ ì‹œì‘")
        news_items = get_live_news()
        count = 0
        for title, link, press in news_items:
            if link not in old_links:
                send_telegram(title, link, press)
                log_to_sheet(sheet, title, link, press)
                old_links.append(link)
                count += 1
                time.sleep(1)
                if count >= MAX_SEND_PER_LOOP:
                    break
        save_old_links(old_links)
        time.sleep(60)

# ë§í¬ ìºì‹œ
def load_old_links():
    try:
        with open(LINK_CACHE_FILE, 'r') as f:
            return json.load(f)
    except:
        return []

def save_old_links(links):
    with open(LINK_CACHE_FILE, 'w') as f:
        json.dump(links[-100:], f)

# ì‹¤í–‰
threading.Thread(target=news_loop, daemon=True).start()

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port)
