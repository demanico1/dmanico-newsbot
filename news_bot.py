import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os

# ë””ë§ˆë‹ˆì½” ì •ë³´
BOT_TOKEN = '8059473480:AAHWayTZDViTfTk-VtCAmPxvYAmTrjhtMMs'
CHAT_ID = '2037756724'
SHEET_NAME = 'ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ íŠ¸ë˜ì»¤'
MAX_SEND_PER_LOOP = 5  # ë£¨í”„ë‹¹ ìµœëŒ€ ë‰´ìŠ¤ ì „ì†¡ ìˆ˜

# êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_google_sheet(sheet_name):
    key_json = os.environ.get('GOOGLE_KEY_JSON')
    if not key_json:
        print("âŒ GOOGLE_KEY_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ!")
        exit()
    key_dict = json.loads(key_json)
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    client = gspread.authorize(creds)
    return client.open(sheet_name)

sheet = connect_google_sheet(SHEET_NAME)

# ë‚ ì§œë³„ ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸°
def get_daily_worksheet(sheet):
    today = datetime.now().strftime('%Y-%m-%d')
    try:
        worksheet = sheet.worksheet(today)
    except gspread.exceptions.WorksheetNotFound:
        worksheet = sheet.add_worksheet(title=today, rows="1000", cols="4")
        worksheet.append_row(["ê¸°ë¡ì‹œê°„", "ì„¹ì…˜", "ë‰´ìŠ¤ì œëª©", "ë§í¬"])
    return worksheet

# ì‹œíŠ¸ ê¸°ë¡
def log_to_sheet(sheet, section, title, link):
    worksheet = get_daily_worksheet(sheet)
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    worksheet.append_row([now, section, title, link])
    print(f"[ì‹œíŠ¸ ê¸°ë¡ë¨] {title}")

# ë„¤ì´ë²„ ë­í‚¹ ë‰´ìŠ¤ í¬ë¡¤ë§
def get_ranking_news():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, 'html.parser')

    news_list = []
    sections = soup.select(".rankingnews_box")

    for section in sections:
        section_title = section.select_one("h4.rankingnews_box_title").get_text(strip=True)
        for rank, li in enumerate(section.select("li"), 1):
            a_tag = li.select_one("a")
            img_tag = li.select_one("img")
            if a_tag:
                title = a_tag.get_text(strip=True)
                link = a_tag['href']
                img_url = img_tag['src'] if img_tag else None
                news_list.append((section_title, rank, title, link, img_url))
    return news_list

# í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram(section, rank, title, link, img_url=None):
    message = f"""ğŸ“¢ <b>[{section} TOP {rank}]</b>\n\n{title}\n{link}"""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto" if img_url else f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'caption': message if img_url else None,
        'photo': img_url if img_url else None,
        'text': None if img_url else message,
        'parse_mode': 'HTML',
        'disable_web_page_preview': False
    }
    try:
        response = requests.post(url, data={k: v for k, v in data.items() if v is not None})
        if response.status_code == 429:
            retry_after = response.json().get("parameters", {}).get("retry_after", 60)
            print(f"ğŸ” ë„ˆë¬´ ë§ì€ ìš”ì²­! {retry_after}ì´ˆ ëŒ€ê¸°")
            time.sleep(retry_after + 1)
        else:
            print(f"[í…”ë ˆê·¸ë¨ ì‘ë‹µ] {response.text}")
    except Exception as e:
        print(f"[í…”ë ˆê·¸ë¨ ì—ëŸ¬] {e}")

# ì‹¤í–‰ ë£¨í”„
old_links = []
while True:
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ë£¨í”„ ì‘ë™ ì¤‘...")
    news_items = get_ranking_news()
    count = 0
    for section, rank, title, link, img_url in news_items:
        if link not in old_links:
            send_telegram(section, rank, title, link, img_url)
            log_to_sheet(sheet, section, title, link)
            old_links.append(link)
            count += 1
            if count >= MAX_SEND_PER_LOOP:
                print("âš ï¸ ì „ì†¡ ì œí•œ ë„ë‹¬. ë‹¤ìŒ ë£¨í”„ê¹Œì§€ ëŒ€ê¸°.")
                break
            time.sleep(1)  # ë‰´ìŠ¤ ê°„ ìµœì†Œ 1ì´ˆ ê°„ê²©
    if len(old_links) > 100:
        old_links = old_links[-50:]
    time.sleep(60)
