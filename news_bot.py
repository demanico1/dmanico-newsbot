# -*- coding: utf-8 -*-
import threading
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os
from flask import Flask
import pandas as pd

# ğŸ” ë””ë§ˆë‹ˆì½” ì„¤ì •
BOT_TOKEN = '8059473480:AAHWayTZDViTfTk-VtCAmPxvYAmTrjhtMMs'
CHAT_ID = '2037756724'
SHEET_NAME = 'ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ íŠ¸ë˜ì»¤'

# ğŸŒ Flask ì„œë²„ (Renderìš© ìœ ì§€)
app = Flask(__name__)
@app.route('/')
def home():
    return "ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤ë´‡ ì‘ë™ ì¤‘!"
def run_flask():
    app.run(host='0.0.0.0', port=10000)

# ğŸ“¦ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
def get_krx_stock_list():
    url = "https://kind.krx.co.kr/corpgeneral/corpList.do?method=download"
    df = pd.read_html(url, encoding='cp949')[0]
    df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].apply(lambda x: f"{x:06d}")
    return dict(zip(df['íšŒì‚¬ëª…'], df['ì¢…ëª©ì½”ë“œ']))

stock_dict = get_krx_stock_list()

# ğŸ” ë‰´ìŠ¤ ë³¸ë¬¸ì—ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
def extract_stock_from_article(title, url, stock_dict):
    text = title
    try:
        res = requests.get(url, timeout=3)
        soup = BeautifulSoup(res.text, 'html.parser')
        text += soup.get_text()
    except:
        pass
    for name in stock_dict.keys():
        if name in text:
            return name, stock_dict[name]
    return None, None

# âœ… í”„ë¦¬ë·° ì§€ì› ë§¤ì²´ í•„í„°
def preview_supported(url):
    return any(domain in url for domain in [
        "n.news.naver.com", "biz.chosun.com", "news.mt.co.kr",
        "news.mk.co.kr", "hankyung.com", "fnnews.com",
        "biz.heraldcorp.com", "edaily.co.kr", "sedaily.com"
    ])

# ğŸ“¥ ê° ë§¤ì²´ë³„ ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜
def get_naver_finance():
    url = "https://finance.naver.com/news/mainnews.naver"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, "html.parser")
    return [("https://finance.naver.com" + a['href'], a.get_text(strip=True)) for a in soup.select(".mainNewsList li a")]

def get_naver_ranking():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, "html.parser")
    return [("https://news.naver.com" + a['href'], a.get_text(strip=True)) for a in soup.select("ul.ranking_list li a")]

def get_chosunbiz():
    url = "https://biz.chosun.com/"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, "html.parser")
    return [(a['href'], a.get_text(strip=True)) for a in soup.select("a") if a.get('href', '').startswith("https://biz.chosun.com")]

def get_mt():
    url = "https://news.mt.co.kr/newsList.html?sec=sisa&sec2=&pageNum=1"
    res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(res.text, "html.parser")
    return [("https://news.mt.co.kr" + a['href'], a.get_text(strip=True)) for a in soup.select("ul.list_news a") if a['href'].startswith("/mtview")]

# ğŸ“Š êµ¬ê¸€ì‹œíŠ¸ ì—°ê²°
def connect_sheet():
    key_json = os.environ.get('GOOGLE_KEY_JSON')
    if not key_json:
        print("âŒ GOOGLE_KEY_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ!")
        exit()
    key_dict = json.loads(key_json)
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    return gspread.authorize(creds).open(SHEET_NAME).sheet1

sheet = connect_sheet()

# ğŸ“ ì‹œíŠ¸ ê¸°ë¡
def log_to_sheet(sheet, title, link):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sheet.append_row([now, title, link])
    print(f"[ì‹œíŠ¸ ê¸°ë¡ë¨] {title}")

# ğŸš€ í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram_news(title, link):
    message = f"""[ë””ë§ˆë‹ˆì½” ë‰´ìŠ¤]

{title}
{link}
"""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'text': message,
        'parse_mode': 'HTML',
        'disable_web_page_preview': False
    }
    response = requests.post(url, data=data)
    print(f"[í…”ë ˆê·¸ë¨ ì‘ë‹µ] {response.text}")

# ğŸ”„ ë©”ì¸ ë£¨í”„
def start_news_loop():
    old_links = []
    while True:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ë£¨í”„ ëŒê³  ìˆìŒ...")

        all_news = []
        for fn in [get_naver_finance, get_naver_ranking, get_chosunbiz, get_mt]:
            try:
                all_news += fn()
            except Exception as e:
                print(f"[ì—ëŸ¬] {fn.__name__}: {e}")

        for link, title in all_news:
            if link not in old_links and preview_supported(link):
                stock_name, stock_code = extract_stock_from_article(title, link, stock_dict)
                if stock_name:
                    title = f"[{stock_name}] {title}"
                    send_telegram_news(title, link)
                    log_to_sheet(sheet, title, link)
                    old_links.append(link)
                    if len(old_links) > 50:
                        old_links.pop(0)

        time.sleep(60)

# ğŸ” ì‹¤í–‰ ì‹œì‘
if __name__ == "__main__":
    threading.Thread(target=run_flask).start()
    threading.Thread(target=start_news_loop).start()
